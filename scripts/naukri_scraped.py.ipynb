{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84a801c-6254-4f6c-ad36-6561ca93fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.35.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2025.8.3)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.30.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.30.0->selenium) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.4.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.23)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium pandas openpyxl webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798c2213-9d2e-4516-810a-880e33272375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c5c391-9a9a-457f-b3fd-c53f730c8dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chrome driver ready!\n"
     ]
    }
   ],
   "source": [
    "#Initialize Selenium Chrome Driver\n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--log-level=3\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.set_window_size(1200, 900)\n",
    "    return driver\n",
    "\n",
    "driver = get_driver()\n",
    "print(\"✅ Chrome driver ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b54a369-0551-4021-ab5b-a07e4cce222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define job scraping function\n",
    "roles = [\n",
    "    \"data-analyst\",\n",
    "    \"data-scientist\",\n",
    "    \"business-analyst\",\n",
    "    \"machine-learning-engineer\",\n",
    "    \"python-developer\",\n",
    "    \"data-engineer\"\n",
    "]\n",
    "\n",
    "def scrape_jobs(role, num_pages=3):  # you can increase num_pages later\n",
    "    all_jobs = []\n",
    "\n",
    "    for page in range(1, num_pages + 1):\n",
    "        url = f\"https://www.naukri.com/{role}-jobs-in-india-{page}\"\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            job_cards = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.cust-job-tuple\"))\n",
    "            )\n",
    "        except:\n",
    "            print(f\"⚠️ No jobs found for {role} page {page}\")\n",
    "            continue\n",
    "\n",
    "        for job in job_cards:\n",
    "            try: title = job.find_element(By.CSS_SELECTOR, \"a.title\").text\n",
    "            except: title = \"N/A\"\n",
    "            try: company = job.find_element(By.CSS_SELECTOR, \"a.comp-name\").text\n",
    "            except: company = \"N/A\"\n",
    "            try: location = job.find_element(By.CSS_SELECTOR, \"span.locWdth\").text\n",
    "            except: location = \"N/A\"\n",
    "            try: experience = job.find_element(By.CSS_SELECTOR, \"span.expwdth\").text\n",
    "            except: experience = \"N/A\"\n",
    "            try: salary = job.find_element(By.CSS_SELECTOR, \"span.salary, span.sal-wrap\").text\n",
    "            except: salary = \"N/A\"\n",
    "            try: skills = \", \".join([s.text for s in job.find_elements(By.CSS_SELECTOR, \"ul.tags-gt li\")])\n",
    "            except: skills = \"N/A\"\n",
    "            try: posted_date = job.find_element(By.CSS_SELECTOR, \"span.job-post-day\").text\n",
    "            except: posted_date = \"N/A\"\n",
    "\n",
    "            all_jobs.append({\n",
    "                \"Role\": role.replace(\"-\", \" \").title(),\n",
    "                \"Job Title\": title,\n",
    "                \"Company\": company,\n",
    "                \"Location\": location,\n",
    "                \"Experience\": experience,\n",
    "                \"Salary\": salary,\n",
    "                \"Skills\": skills,\n",
    "                \"Posted Date\": posted_date\n",
    "            })\n",
    "\n",
    "        print(f\"✅ {role} - Page {page} scraped\")\n",
    "    \n",
    "    return all_jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7c6a6b-3c18-4501-b0b3-5ed49dd17a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Scraping data-analyst - Page 1 ...\n",
      "✅ data-analyst - Page 1 scraped\n",
      "🔍 Scraping data-analyst - Page 2 ...\n",
      "✅ data-analyst - Page 2 scraped\n",
      "🔍 Scraping data-analyst - Page 3 ...\n",
      "✅ data-analyst - Page 3 scraped\n",
      "🔍 Scraping data-analyst - Page 4 ...\n",
      "✅ data-analyst - Page 4 scraped\n",
      "🔍 Scraping data-analyst - Page 5 ...\n",
      "✅ data-analyst - Page 5 scraped\n",
      "🔍 Scraping data-analyst - Page 6 ...\n",
      "✅ data-analyst - Page 6 scraped\n",
      "🔍 Scraping data-analyst - Page 7 ...\n",
      "✅ data-analyst - Page 7 scraped\n",
      "🔍 Scraping data-analyst - Page 8 ...\n",
      "✅ data-analyst - Page 8 scraped\n",
      "🔍 Scraping data-analyst - Page 9 ...\n",
      "✅ data-analyst - Page 9 scraped\n",
      "🔍 Scraping data-analyst - Page 10 ...\n",
      "✅ data-analyst - Page 10 scraped\n",
      "🔍 Scraping data-scientist - Page 1 ...\n",
      "✅ data-scientist - Page 1 scraped\n",
      "🔍 Scraping data-scientist - Page 2 ...\n",
      "✅ data-scientist - Page 2 scraped\n",
      "🔍 Scraping data-scientist - Page 3 ...\n",
      "✅ data-scientist - Page 3 scraped\n",
      "🔍 Scraping data-scientist - Page 4 ...\n",
      "✅ data-scientist - Page 4 scraped\n",
      "🔍 Scraping data-scientist - Page 5 ...\n",
      "✅ data-scientist - Page 5 scraped\n",
      "🔍 Scraping data-scientist - Page 6 ...\n",
      "✅ data-scientist - Page 6 scraped\n",
      "🔍 Scraping data-scientist - Page 7 ...\n",
      "✅ data-scientist - Page 7 scraped\n",
      "🔍 Scraping data-scientist - Page 8 ...\n",
      "✅ data-scientist - Page 8 scraped\n",
      "🔍 Scraping data-scientist - Page 9 ...\n",
      "✅ data-scientist - Page 9 scraped\n",
      "🔍 Scraping data-scientist - Page 10 ...\n",
      "✅ data-scientist - Page 10 scraped\n",
      "🔍 Scraping business-analyst - Page 1 ...\n",
      "✅ business-analyst - Page 1 scraped\n",
      "🔍 Scraping business-analyst - Page 2 ...\n",
      "✅ business-analyst - Page 2 scraped\n",
      "🔍 Scraping business-analyst - Page 3 ...\n",
      "✅ business-analyst - Page 3 scraped\n",
      "🔍 Scraping business-analyst - Page 4 ...\n",
      "✅ business-analyst - Page 4 scraped\n",
      "🔍 Scraping business-analyst - Page 5 ...\n",
      "✅ business-analyst - Page 5 scraped\n",
      "🔍 Scraping business-analyst - Page 6 ...\n",
      "✅ business-analyst - Page 6 scraped\n",
      "🔍 Scraping business-analyst - Page 7 ...\n",
      "✅ business-analyst - Page 7 scraped\n",
      "🔍 Scraping business-analyst - Page 8 ...\n",
      "✅ business-analyst - Page 8 scraped\n",
      "🔍 Scraping business-analyst - Page 9 ...\n",
      "✅ business-analyst - Page 9 scraped\n",
      "🔍 Scraping business-analyst - Page 10 ...\n",
      "✅ business-analyst - Page 10 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 1 ...\n",
      "✅ machine-learning-engineer - Page 1 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 2 ...\n",
      "✅ machine-learning-engineer - Page 2 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 3 ...\n",
      "✅ machine-learning-engineer - Page 3 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 4 ...\n",
      "✅ machine-learning-engineer - Page 4 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 5 ...\n",
      "✅ machine-learning-engineer - Page 5 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 6 ...\n",
      "✅ machine-learning-engineer - Page 6 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 7 ...\n",
      "✅ machine-learning-engineer - Page 7 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 8 ...\n",
      "✅ machine-learning-engineer - Page 8 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 9 ...\n",
      "✅ machine-learning-engineer - Page 9 scraped\n",
      "🔍 Scraping machine-learning-engineer - Page 10 ...\n",
      "✅ machine-learning-engineer - Page 10 scraped\n",
      "🔍 Scraping python-developer - Page 1 ...\n",
      "✅ python-developer - Page 1 scraped\n",
      "🔍 Scraping python-developer - Page 2 ...\n",
      "✅ python-developer - Page 2 scraped\n",
      "🔍 Scraping python-developer - Page 3 ...\n",
      "✅ python-developer - Page 3 scraped\n",
      "🔍 Scraping python-developer - Page 4 ...\n",
      "✅ python-developer - Page 4 scraped\n",
      "🔍 Scraping python-developer - Page 5 ...\n",
      "✅ python-developer - Page 5 scraped\n",
      "🔍 Scraping python-developer - Page 6 ...\n",
      "✅ python-developer - Page 6 scraped\n",
      "🔍 Scraping python-developer - Page 7 ...\n",
      "✅ python-developer - Page 7 scraped\n",
      "🔍 Scraping python-developer - Page 8 ...\n",
      "✅ python-developer - Page 8 scraped\n",
      "🔍 Scraping python-developer - Page 9 ...\n",
      "✅ python-developer - Page 9 scraped\n",
      "🔍 Scraping python-developer - Page 10 ...\n",
      "✅ python-developer - Page 10 scraped\n",
      "🔍 Scraping data-engineer - Page 1 ...\n",
      "✅ data-engineer - Page 1 scraped\n",
      "🔍 Scraping data-engineer - Page 2 ...\n",
      "✅ data-engineer - Page 2 scraped\n",
      "🔍 Scraping data-engineer - Page 3 ...\n",
      "✅ data-engineer - Page 3 scraped\n",
      "🔍 Scraping data-engineer - Page 4 ...\n",
      "✅ data-engineer - Page 4 scraped\n",
      "🔍 Scraping data-engineer - Page 5 ...\n",
      "✅ data-engineer - Page 5 scraped\n",
      "🔍 Scraping data-engineer - Page 6 ...\n",
      "✅ data-engineer - Page 6 scraped\n",
      "🔍 Scraping data-engineer - Page 7 ...\n",
      "✅ data-engineer - Page 7 scraped\n",
      "🔍 Scraping data-engineer - Page 8 ...\n",
      "✅ data-engineer - Page 8 scraped\n",
      "🔍 Scraping data-engineer - Page 9 ...\n",
      "✅ data-engineer - Page 9 scraped\n",
      "🔍 Scraping data-engineer - Page 10 ...\n",
      "✅ data-engineer - Page 10 scraped\n",
      "✅ Scraping finished. Total records: 1202\n"
     ]
    }
   ],
   "source": [
    "all_jobs_data = []\n",
    "\n",
    "for role in roles:\n",
    "    jobs = scrape_jobs(role, num_pages=10)  # 🔧 increase num_pages for more data\n",
    "    all_jobs_data.extend(jobs)\n",
    "\n",
    "df = pd.DataFrame(all_jobs_data)\n",
    "print(\"✅ Scraping finished. Total records:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51cfd6ba-1460-42d2-bdec-438055fc67a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Posted Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Client Data Analyst</td>\n",
       "      <td>JPMorgan Chase Bank</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1-7 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>interviewing, service operations, data analysi...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Client Data Analyst</td>\n",
       "      <td>JPMorgan Chase Bank</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1-7 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>data analysis, data analytics, business requir...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Data Analysis, Sales Report, Power Bi, Advance...</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Client Data Analyst</td>\n",
       "      <td>JPMorgan Chase Bank</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1-7 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Operational risk, Compliance, Data collection,...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Zero Gravity Photography</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Usage, Business reporting, Data Analyst, Manag...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Convegenius Edu</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>database maintenance, python, data analytics, ...</td>\n",
       "      <td>2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Leading Client</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>python, sql, pandas, tableau, basic sql, chart...</td>\n",
       "      <td>2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Company Data Analyst</td>\n",
       "      <td>MSCI Services</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>database management, python, data analysis, da...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Opening For data analyst SME / TM @Hyderabad</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Data Analytics, Power Bi, SAS, VBA, mis, Snowf...</td>\n",
       "      <td>6 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cloudtara Technologies</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>database maintenance, python, data analytics, ...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Aroha Technologies</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Data Analyst, Data, Data analysis</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst, Corporate Audit</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>data analysis, data analytics, data manipulati...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hexaware Technologies</td>\n",
       "      <td>Hybrid - Pune, Chennai, Bengaluru</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>13-18 Lacs PA</td>\n",
       "      <td>Data Warehousing, ETL, SQL, Warehouse, Data, D...</td>\n",
       "      <td>2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>S&amp;P Global Market Intelligence</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>data analysis, supply chain, process improveme...</td>\n",
       "      <td>2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst (SWAT) - NCT</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>python, data analysis, sql, data quality, etl,...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Disc Technology Services</td>\n",
       "      <td>Mumbai, Hyderabad, New Delhi, Chennai, Bengaluru</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>master data, metadata, python, data analysis, ...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst - L4</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>data analysis, data warehousing, warehouse, in...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>C2fo India Technologies</td>\n",
       "      <td>Noida</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "      <td>6-8.5 Lacs PA</td>\n",
       "      <td>Power Bi Reports, SQL, Python, Dax Queries, Po...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>S&amp;C GN - Data&amp;AI - Resources - Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>python, data analysis, machine learning, artif...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Emids Technologies</td>\n",
       "      <td>Noida, Hyderabad, Bengaluru</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "      <td>N/A</td>\n",
       "      <td>SQL, Python, Data Analytics, Analytics, Data, ...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Role                                     Job Title  \\\n",
       "0   Data Analyst                           Client Data Analyst   \n",
       "1   Data Analyst                           Client Data Analyst   \n",
       "2   Data Analyst                                  Data Analyst   \n",
       "3   Data Analyst                           Client Data Analyst   \n",
       "4   Data Analyst                                  Data Analyst   \n",
       "5   Data Analyst                                  Data Analyst   \n",
       "6   Data Analyst                                  Data Analyst   \n",
       "7   Data Analyst                          Company Data Analyst   \n",
       "8   Data Analyst  Opening For data analyst SME / TM @Hyderabad   \n",
       "9   Data Analyst                                  Data Analyst   \n",
       "10  Data Analyst                                  Data Analyst   \n",
       "11  Data Analyst                 Data Analyst, Corporate Audit   \n",
       "12  Data Analyst                                  Data Analyst   \n",
       "13  Data Analyst                                  Data Analyst   \n",
       "14  Data Analyst                     Data Analyst (SWAT) - NCT   \n",
       "15  Data Analyst                                  Data Analyst   \n",
       "16  Data Analyst                             Data Analyst - L4   \n",
       "17  Data Analyst                                  Data Analyst   \n",
       "18  Data Analyst        S&C GN - Data&AI - Resources - Analyst   \n",
       "19  Data Analyst                                  Data Analyst   \n",
       "\n",
       "                           Company  \\\n",
       "0              JPMorgan Chase Bank   \n",
       "1              JPMorgan Chase Bank   \n",
       "2        Tata Consultancy Services   \n",
       "3              JPMorgan Chase Bank   \n",
       "4         Zero Gravity Photography   \n",
       "5                  Convegenius Edu   \n",
       "6                   Leading Client   \n",
       "7                    MSCI Services   \n",
       "8                        Cognizant   \n",
       "9           Cloudtara Technologies   \n",
       "10              Aroha Technologies   \n",
       "11                         Cargill   \n",
       "12           Hexaware Technologies   \n",
       "13  S&P Global Market Intelligence   \n",
       "14                   Deutsche Bank   \n",
       "15        Disc Technology Services   \n",
       "16                           Wipro   \n",
       "17         C2fo India Technologies   \n",
       "18                       Accenture   \n",
       "19              Emids Technologies   \n",
       "\n",
       "                                            Location Experience  \\\n",
       "0                                          Bengaluru    1-7 Yrs   \n",
       "1                                          Bengaluru    1-7 Yrs   \n",
       "2                                            Chennai    3-8 Yrs   \n",
       "3                                          Bengaluru    1-7 Yrs   \n",
       "4                                            Chennai    0-2 Yrs   \n",
       "5                                             Jaipur    0-3 Yrs   \n",
       "6                                          Bengaluru    2-5 Yrs   \n",
       "7                                             Mumbai    1-4 Yrs   \n",
       "8                                          Hyderabad    3-6 Yrs   \n",
       "9                                          Bengaluru    1-3 Yrs   \n",
       "10                                         Bengaluru    0-3 Yrs   \n",
       "11                                          Gurugram    2-5 Yrs   \n",
       "12                 Hybrid - Pune, Chennai, Bengaluru   8-12 Yrs   \n",
       "13                                         Bengaluru    3-5 Yrs   \n",
       "14                                         Bengaluru    1-4 Yrs   \n",
       "15  Mumbai, Hyderabad, New Delhi, Chennai, Bengaluru    3-5 Yrs   \n",
       "16                                         Bengaluru    5-8 Yrs   \n",
       "17                                             Noida    1-4 Yrs   \n",
       "18                                         Bengaluru    4-8 Yrs   \n",
       "19                       Noida, Hyderabad, Bengaluru   8-10 Yrs   \n",
       "\n",
       "           Salary                                             Skills  \\\n",
       "0             N/A  interviewing, service operations, data analysi...   \n",
       "1             N/A  data analysis, data analytics, business requir...   \n",
       "2             N/A  Data Analysis, Sales Report, Power Bi, Advance...   \n",
       "3             N/A  Operational risk, Compliance, Data collection,...   \n",
       "4             N/A  Usage, Business reporting, Data Analyst, Manag...   \n",
       "5             N/A  database maintenance, python, data analytics, ...   \n",
       "6             N/A  python, sql, pandas, tableau, basic sql, chart...   \n",
       "7             N/A  database management, python, data analysis, da...   \n",
       "8             N/A  Data Analytics, Power Bi, SAS, VBA, mis, Snowf...   \n",
       "9             N/A  database maintenance, python, data analytics, ...   \n",
       "10            N/A                  Data Analyst, Data, Data analysis   \n",
       "11            N/A  data analysis, data analytics, data manipulati...   \n",
       "12  13-18 Lacs PA  Data Warehousing, ETL, SQL, Warehouse, Data, D...   \n",
       "13            N/A  data analysis, supply chain, process improveme...   \n",
       "14            N/A  python, data analysis, sql, data quality, etl,...   \n",
       "15            N/A  master data, metadata, python, data analysis, ...   \n",
       "16            N/A  data analysis, data warehousing, warehouse, in...   \n",
       "17  6-8.5 Lacs PA  Power Bi Reports, SQL, Python, Dax Queries, Po...   \n",
       "18            N/A  python, data analysis, machine learning, artif...   \n",
       "19            N/A  SQL, Python, Data Analytics, Analytics, Data, ...   \n",
       "\n",
       "   Posted Date  \n",
       "0    1 day ago  \n",
       "1    1 day ago  \n",
       "2   1 week ago  \n",
       "3    1 day ago  \n",
       "4    1 day ago  \n",
       "5   2 days ago  \n",
       "6   2 days ago  \n",
       "7    1 day ago  \n",
       "8   6 days ago  \n",
       "9    1 day ago  \n",
       "10   1 day ago  \n",
       "11   1 day ago  \n",
       "12  2 days ago  \n",
       "13  2 days ago  \n",
       "14   1 day ago  \n",
       "15   1 day ago  \n",
       "16   1 day ago  \n",
       "17   1 day ago  \n",
       "18   1 day ago  \n",
       "19   1 day ago  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a855fa8-2261-46b1-b5d0-7263bc9f64b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Data saved to data/raw/naukri_jobs.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(r\"D:\\PROJECTS\\Naukri_Job_Trends\\data\\raw\\naukri_jobs_raw.csv\", index=False)\n",
    "print(\"📁 Data saved to data/raw/naukri_jobs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d354579-559f-4a83-8045-55b14d701e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be889c-a727-427b-9031-4ddd459e62ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcc0eb-ecfd-4b95-89cc-7dc38d713aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
